{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExtractTextFromPDF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "HBJLjX3881Cw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para o tutorial a seguir, é necessário a instalação das bibliotecas **PyPDF2** e **textract**\n",
        "Para instalar a **PyPDF2** eu utilizei o pip install pypdf2 (Para executar esse comando no Colab Research, é necessário incluir o sinal de **!** antes da linha de comando)"
      ]
    },
    {
      "metadata": {
        "id": "G072jFHK9OSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Descomente a linha abaixo, caso não tenha o pypdf2 disponível para utilização\n",
        "#!pip install pypdf2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-gzDBna9WQD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para a instalação do textract, precisei instalar todos as dependências no Colab Research que também nos permite a instalar de pacotes **.deb** utilizando o comando **!apt-get install [1].deb [2].deb**"
      ]
    },
    {
      "metadata": {
        "id": "dZdf_3PW9t1x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Descomente a linha abaixo para executar\n",
        "#!apt-get install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Si8MSMS99wC5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Após instalar as dependências acima, ainda estava reclamando para instalar o textract no Colab Research. Percebi que faltava uma dependência que foi instalada conforme a seguir:"
      ]
    },
    {
      "metadata": {
        "id": "K2xwWBO897ZU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Descomente a linha abaixo para executar\n",
        "#!apt-get install libpulse-dev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5T9JJDKj99eb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Por fim, foi possível instalar a biblioteca de extração utilizando o **pip install**"
      ]
    },
    {
      "metadata": {
        "id": "Gs7ZX3qR-FU3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Descomente a linha abaixo para executar\n",
        "#!pip install textract"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rd-NQqTnoD8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Bibliotecas utilizadas para leitura do PDF e extração de propriedades\n",
        "import PyPDF2 \n",
        "import textract\n",
        "#Biblioteca utilizada para processamento de linguagem natural\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SI9LOG0-_OEJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Crie uma variável para receber o nome do arquivo PDF que irá realizar a extração dos termos, no exemplo utilizei um nome aleatório, como podem ver a seguir.\n",
        "\n",
        "O script iniciado a partir dessa variável pode ser envolvido em um loop para que seja possível extrair os termos de vários documentos ao mesmo tempo."
      ]
    },
    {
      "metadata": {
        "id": "jcxJBZ8Z_Zhj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = 'no18061801.pdf'\n",
        "pdfFileObj = open(filename, 'rb')\n",
        "\n",
        "#A variável pdfReader é um objeto legível que será analisado\n",
        "pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
        "\n",
        "#num_pages irá armazenar o número de páginas que o PDF possui, para que possamos navegar entre as páginas\n",
        "num_pages = pdfReader.numPages\n",
        "count = 0\n",
        "text = \"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wXJA3vp5DAdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A estrutura de repetição a seguir irá recuperar e acumular uma variável todo o conteúdo do documento"
      ]
    },
    {
      "metadata": {
        "id": "0BFi_wpHDIuE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "while count < num_pages:\n",
        "    pageObj = pdfReader.getPage(count)\n",
        "    count +=1\n",
        "    text += pageObj.extractText()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IDTmpxDPDaI-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Faremos um teste para verificar se houve texto recuperado do PDF, caso não tenha sido recuperado texto algum, iremos aplicar um método de OCR pois há a possibilidade que o PDF possua páginas escaneadas no formato de imagens"
      ]
    },
    {
      "metadata": {
        "id": "BSYekeGCDtPw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if text != \"\":\n",
        "   text = text\n",
        "else:\n",
        "   text = textract.process(fileurl, method='tesseract', language='por')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRtgYvo3D1D0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Utilizando o método **word_tokenize** da biblioteca nltk.tokenize, converteremos toda a estrutura textual em um arranjo onde cada elemento será uma palavra"
      ]
    },
    {
      "metadata": {
        "id": "o4UXBZhIEW0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-T4JyP9lEZff",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Criaremos uma lista que contém as pontuações que serão removidas do texto"
      ]
    },
    {
      "metadata": {
        "id": "2-IlRqI8EgH9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "punctuations = ['(',')',';',':','[',']',',','.','-','>','<','|']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2qoJLsPzEhQq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inicializaremo uma lista com as stopwords, nesse caso em português, com os termos mais comuns do idioma a serem removidos e desconsiderados"
      ]
    },
    {
      "metadata": {
        "id": "v5FH_WnHEuBt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('portuguese')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZP9u8y8WE9_z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Criaremos uma lista de palavras que não estão nas stopwords e não estão nas pontuações"
      ]
    },
    {
      "metadata": {
        "id": "JJU6Zw2HFMHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "keywords = [word for word in tokens if not word in stop_words and not word in punctuations]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eah1SG-5FOsA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Pronto! Agora podemos utilizar os termos extraídos do arquivo PDF em nosso código de NLP - Natural Language Processing"
      ]
    },
    {
      "metadata": {
        "id": "Q_uyQjJKFco6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for k in keywords:\n",
        "\tprint k"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}